{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Implementation : Word embedding layer with keras\n",
    "- we will take some example then convert to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentences first use one_hot encoding, these are our set of questions\n",
    "sent=['the glass of milk' ,\n",
    "'the glass of juice',\n",
    "'the cup of tea ',\n",
    "'I am a good boy',\n",
    "'I am a good developer' ,\n",
    "'understand the meaning of words',\n",
    "'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea ',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define vocabulary size\n",
    "voc_size=10000 # lets take 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the glass of milk\n"
     ]
    }
   ],
   "source": [
    "for words in sent:\n",
    "    print(words)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4411, 5492, 9052, 2396],\n",
       " [4411, 5492, 9052, 6064],\n",
       " [4411, 8477, 9052, 6011],\n",
       " [5873, 2067, 208, 7073, 2734],\n",
       " [5873, 2067, 208, 7073, 397],\n",
       " [6587, 4411, 2788, 9052, 9531],\n",
       " [5614, 825, 3461, 7073]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## one hot Representation\n",
    "## make list comprehension we pass words(each sentence at a time) in sent to one hot along with vocab size\n",
    "one_hot_repr=[one_hot(words,voc_size) for words in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above representation means we convert each sentence in index at which these words are \n",
    "# in our 10000 vovab size means \"the\" present at 4411 index, \"glass\" present at 5492 index and so on\n",
    "# so if we write a vector of glass it will be (10000,1) vector with 1 at index 5492 and rest values 0 \n",
    "# similarly for other words\n",
    "# above we can see that the first two sentence are quite similar and thats why we see indexes are same \n",
    "# and only last index is different\n",
    "\n",
    "# so now if say consider our 300 feature dimension example where we have vocab words like\n",
    "#  boy,king,girl,queen,apple,banana\n",
    "# and convert this 300 to 2 dimension using PCA and plot it we see boy and king will be close, girl and \n",
    "# queen will be close, apple and banana will be close\n",
    "# and here only out important algo \"consine similarity\" gets apllied and this has important use \n",
    "# case in recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we direclty can use one_hot as we discuss about its problem we create and embedding layer\n",
    "## word embedding representation\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # talk later\n",
    "from tensorflow.keras.models import Sequential # since we are creating a sequential model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea ',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 4411 5492 9052 2396]\n",
      " [   0    0    0    0 4411 5492 9052 6064]\n",
      " [   0    0    0    0 4411 8477 9052 6011]\n",
      " [   0    0    0 5873 2067  208 7073 2734]\n",
      " [   0    0    0 5873 2067  208 7073  397]\n",
      " [   0    0    0 6587 4411 2788 9052 9531]\n",
      " [   0    0    0    0 5614  825 3461 7073]]\n"
     ]
    }
   ],
   "source": [
    "## pad_sequences we use this since all sentences can have different number of words so we use \n",
    "# pad_sequnce to pad them to same length as all words of sentence will go with a fixed number of time \n",
    "# stamp in RNN\n",
    "set_length_max=8 # we set is for padding according to our dataset sent since here max words in sentence is 5 so 8 for safer side\n",
    "# give it our one_hot_reps and apply prepadding padding added at start and also maxlen each sentence should be\n",
    "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=set_length_max)\n",
    "print(embedded_docs) # we can see now our representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature representation\n",
    "dim=10 # i.e we have 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Pythonproject\\pythonproject\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create a sequential model\n",
    "model=Sequential()\n",
    "# inside model add Embedding layer by giving voc_size,dim,input_length it internally use word2vec\n",
    "model.add(Embedding(voc_size,dim,input_length=set_length_max))\n",
    "## train this model with optimizer adam and loss function mse\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now see our model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [ 3.06217708e-02,  2.10681222e-02,  1.44317262e-02,\n",
       "         -4.20122035e-02,  1.52206458e-02,  1.22934580e-02,\n",
       "         -2.64960770e-02,  1.37637742e-02,  4.70125712e-02,\n",
       "          1.91196054e-03],\n",
       "        [-3.07950135e-02,  3.99215482e-02, -4.07329202e-02,\n",
       "         -3.11972387e-02,  3.18008773e-02,  4.81092073e-02,\n",
       "          2.39833035e-02, -1.35945454e-02,  3.25284898e-04,\n",
       "         -4.60820459e-02],\n",
       "        [-4.43302765e-02,  3.50644849e-02,  7.34164566e-03,\n",
       "         -5.42485714e-03,  2.06167363e-02, -4.88841794e-02,\n",
       "         -1.99206006e-02,  1.41710751e-02,  3.64768244e-02,\n",
       "          2.73646973e-02],\n",
       "        [ 1.48321725e-02, -2.20345333e-03, -1.74295902e-02,\n",
       "         -2.99116261e-02, -1.33447051e-02,  2.98730172e-02,\n",
       "         -1.80278793e-02,  4.47206385e-02, -4.47661802e-03,\n",
       "          1.57626309e-02]],\n",
       "\n",
       "       [[-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [ 3.06217708e-02,  2.10681222e-02,  1.44317262e-02,\n",
       "         -4.20122035e-02,  1.52206458e-02,  1.22934580e-02,\n",
       "         -2.64960770e-02,  1.37637742e-02,  4.70125712e-02,\n",
       "          1.91196054e-03],\n",
       "        [-3.07950135e-02,  3.99215482e-02, -4.07329202e-02,\n",
       "         -3.11972387e-02,  3.18008773e-02,  4.81092073e-02,\n",
       "          2.39833035e-02, -1.35945454e-02,  3.25284898e-04,\n",
       "         -4.60820459e-02],\n",
       "        [-4.43302765e-02,  3.50644849e-02,  7.34164566e-03,\n",
       "         -5.42485714e-03,  2.06167363e-02, -4.88841794e-02,\n",
       "         -1.99206006e-02,  1.41710751e-02,  3.64768244e-02,\n",
       "          2.73646973e-02],\n",
       "        [ 3.55283655e-02, -2.81633865e-02,  3.16183306e-02,\n",
       "          2.16290243e-02, -1.95274111e-02,  3.84986736e-02,\n",
       "          7.23618269e-03,  3.70728262e-02,  1.13206729e-02,\n",
       "          2.58542188e-02]],\n",
       "\n",
       "       [[-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [ 3.06217708e-02,  2.10681222e-02,  1.44317262e-02,\n",
       "         -4.20122035e-02,  1.52206458e-02,  1.22934580e-02,\n",
       "         -2.64960770e-02,  1.37637742e-02,  4.70125712e-02,\n",
       "          1.91196054e-03],\n",
       "        [-4.35946472e-02,  6.86422735e-03,  7.22505897e-03,\n",
       "          3.02627720e-02, -1.27254725e-02,  4.28617038e-02,\n",
       "         -2.85225045e-02, -4.11786437e-02,  1.85398348e-02,\n",
       "          4.52303551e-02],\n",
       "        [-4.43302765e-02,  3.50644849e-02,  7.34164566e-03,\n",
       "         -5.42485714e-03,  2.06167363e-02, -4.88841794e-02,\n",
       "         -1.99206006e-02,  1.41710751e-02,  3.64768244e-02,\n",
       "          2.73646973e-02],\n",
       "        [ 5.72659075e-04,  1.73577406e-02,  3.36018912e-02,\n",
       "         -2.02653557e-03, -1.35388225e-03,  1.76255777e-03,\n",
       "         -1.19075663e-02,  2.47483514e-02, -2.88243424e-02,\n",
       "          2.72597931e-02]],\n",
       "\n",
       "       [[-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-7.08583742e-03,  1.19883418e-02,  1.77202113e-02,\n",
       "          3.91864292e-02,  8.47880915e-03,  3.19684781e-02,\n",
       "         -4.05099615e-02,  1.13817565e-02,  2.11750381e-02,\n",
       "          2.67291702e-02],\n",
       "        [ 3.85753252e-02, -4.36063893e-02, -9.68836620e-03,\n",
       "         -1.00348592e-02, -1.83064826e-02, -2.21574549e-02,\n",
       "          3.24852504e-02,  2.80281641e-02, -3.60264294e-02,\n",
       "          2.18135975e-02],\n",
       "        [ 8.55960697e-03,  4.68644537e-02,  2.34355070e-02,\n",
       "          2.98946984e-02, -7.81043619e-03, -3.34185362e-02,\n",
       "          1.16505250e-02,  1.97742134e-03,  4.18098308e-02,\n",
       "         -2.14200970e-02],\n",
       "        [-9.80184227e-03, -4.70507145e-03, -2.29788423e-02,\n",
       "          7.18818977e-03, -3.09277307e-02, -2.56353505e-02,\n",
       "          2.31369399e-02, -4.83074039e-03,  3.60043161e-02,\n",
       "          4.32829745e-02],\n",
       "        [ 3.09103727e-03,  4.09589745e-02, -4.34872285e-02,\n",
       "          2.52328031e-02, -9.51662660e-05, -2.75816210e-02,\n",
       "          4.29265983e-02, -1.48439407e-03,  4.68686968e-03,\n",
       "         -1.28485076e-02]],\n",
       "\n",
       "       [[-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-7.08583742e-03,  1.19883418e-02,  1.77202113e-02,\n",
       "          3.91864292e-02,  8.47880915e-03,  3.19684781e-02,\n",
       "         -4.05099615e-02,  1.13817565e-02,  2.11750381e-02,\n",
       "          2.67291702e-02],\n",
       "        [ 3.85753252e-02, -4.36063893e-02, -9.68836620e-03,\n",
       "         -1.00348592e-02, -1.83064826e-02, -2.21574549e-02,\n",
       "          3.24852504e-02,  2.80281641e-02, -3.60264294e-02,\n",
       "          2.18135975e-02],\n",
       "        [ 8.55960697e-03,  4.68644537e-02,  2.34355070e-02,\n",
       "          2.98946984e-02, -7.81043619e-03, -3.34185362e-02,\n",
       "          1.16505250e-02,  1.97742134e-03,  4.18098308e-02,\n",
       "         -2.14200970e-02],\n",
       "        [-9.80184227e-03, -4.70507145e-03, -2.29788423e-02,\n",
       "          7.18818977e-03, -3.09277307e-02, -2.56353505e-02,\n",
       "          2.31369399e-02, -4.83074039e-03,  3.60043161e-02,\n",
       "          4.32829745e-02],\n",
       "        [-1.42960921e-02,  1.74305588e-03, -1.21840015e-02,\n",
       "          3.96715738e-02,  3.63386385e-02, -6.18035719e-03,\n",
       "          3.17233317e-02, -1.52368061e-02, -3.97282727e-02,\n",
       "         -1.00466609e-02]],\n",
       "\n",
       "       [[-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [ 4.36471142e-02,  1.84761621e-02,  1.22500770e-02,\n",
       "         -2.90775783e-02,  2.85024382e-02,  2.05401070e-02,\n",
       "          7.24532455e-03, -8.14991072e-03,  2.93022133e-02,\n",
       "         -3.43708619e-02],\n",
       "        [ 3.06217708e-02,  2.10681222e-02,  1.44317262e-02,\n",
       "         -4.20122035e-02,  1.52206458e-02,  1.22934580e-02,\n",
       "         -2.64960770e-02,  1.37637742e-02,  4.70125712e-02,\n",
       "          1.91196054e-03],\n",
       "        [-3.92185934e-02, -4.48480137e-02, -2.60933638e-02,\n",
       "          4.79040854e-02, -2.18330510e-02,  3.41553949e-02,\n",
       "          3.31704654e-02,  4.00765650e-02, -4.34325933e-02,\n",
       "          3.92382219e-03],\n",
       "        [-4.43302765e-02,  3.50644849e-02,  7.34164566e-03,\n",
       "         -5.42485714e-03,  2.06167363e-02, -4.88841794e-02,\n",
       "         -1.99206006e-02,  1.41710751e-02,  3.64768244e-02,\n",
       "          2.73646973e-02],\n",
       "        [-4.30843234e-02,  2.47117318e-02, -3.93233411e-02,\n",
       "          3.34597118e-02,  3.68856452e-02, -3.53289843e-02,\n",
       "         -2.36572269e-02, -3.46939638e-03, -1.42623298e-02,\n",
       "         -4.86728437e-02]],\n",
       "\n",
       "       [[-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-1.06703117e-03, -4.79221605e-02,  1.25568174e-02,\n",
       "          3.36039774e-02,  3.40031274e-02, -1.32556334e-02,\n",
       "         -4.81351614e-02, -1.11858919e-03, -1.41711012e-02,\n",
       "          1.82498619e-03],\n",
       "        [-2.00052503e-02, -3.62506732e-02,  3.10659669e-02,\n",
       "         -3.49359028e-02, -3.77215743e-02, -4.15330157e-02,\n",
       "          3.22851054e-02,  8.90325755e-04,  2.05854289e-02,\n",
       "         -3.32795084e-04],\n",
       "        [-1.46935470e-02,  4.62721027e-02,  4.25118320e-02,\n",
       "         -8.04430246e-03, -8.32705572e-03, -2.39585638e-02,\n",
       "         -2.48391032e-02,  3.46717946e-02,  3.75143178e-02,\n",
       "         -2.08687186e-02],\n",
       "        [ 2.06405260e-02,  4.14896943e-02, -3.52860466e-02,\n",
       "          1.43797286e-02, -3.26337703e-02,  2.25706361e-02,\n",
       "         -6.76541403e-03, -4.80732322e-02,  2.46830322e-02,\n",
       "          4.19966318e-02],\n",
       "        [-9.80184227e-03, -4.70507145e-03, -2.29788423e-02,\n",
       "          7.18818977e-03, -3.09277307e-02, -2.56353505e-02,\n",
       "          2.31369399e-02, -4.83074039e-03,  3.60043161e-02,\n",
       "          4.32829745e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs) # now they are coonverted to vector using embedding layers\n",
    "# we pass padded one_hot_repr words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
